{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0abd01",
   "metadata": {},
   "source": [
    "# Text Preprocessing, Stemming & Lemmatization\n",
    "\n",
    "- Stemming, Lemma. preprocessing steps\n",
    "- reduces a word to their lexical root\n",
    "- techniques used to reduce word variations in the corpus\n",
    "\n",
    "common cleaning steps for text data\n",
    "\n",
    "- remove HTML (use beautiful soup)\n",
    "- convert to lower (reduce word variations) (sometimes helpful May month and may action) (but if use contextuation techniques can be combated)\n",
    "- remove punctuation (use re) (use replace for things like & or @)\n",
    "- replace numbers (standardise outputs)\n",
    "\n",
    "\n",
    "#### Stemming & Lemmatization\n",
    "- uses the suffix of a word, to shrink it down to roots lexical root form\n",
    "\n",
    "#### Stemming\n",
    "- Stemming is an algoritmic process, where ends of words r cut off to arrive at common word\n",
    "- might not always end up with a proper word\n",
    "- use different stemmers (most common one being porter stemmer)\n",
    "- Porter Stemmer is an algorithm with large number of logical rules to stem a word\n",
    "- does have limitations (saw wont get changed to see etc)\n",
    "- english language rules changin for word are v diff so thats why the issue from P.S\n",
    "\n",
    "\n",
    "#### Lemmatization\n",
    "- L uses true covab and structural analysis of the word itself to arrive at true roots (lemma)\n",
    "- L uses pre computed lemma as well as context of word within sentence\n",
    "- WordNet Lemmatizer from NLTK\n",
    "- cons being that it may not be able to generalize new or made up works (text language etc)\n",
    "- so problem if text data doesnt follow proper english (too informal or media data)\n",
    "\n",
    "#### Differences\n",
    "- stemming faster, lemma more computationally exp\n",
    "- but stem poorer quality, lemma higher quality\n",
    "- choose based on analysis context\n",
    "- question of trading off speed versus detail. \n",
    "\n",
    "#### WHY?\n",
    "\n",
    "By performing preprocessing using stemming and lemmatization, coupled with the removal of stop words, we can better reduce our sentences to understand their core meaning. By removing words that do not significantly contribute to the meaning of the sentence and by reducing words to their roots or lemmas, we can efficiently analyze sentences within our deep learning frameworks. \n",
    "\n",
    "- reduces corpus size\n",
    "- improves data quality\n",
    "- speeds up process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f2324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d332b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <b> This text is in bold</br>, <i> This text is in italics </i>\n",
      "Output:  This text is in bold,  This text is in italics \n",
      "Input: ['Cat', 'cat', 'CAT']\n",
      "Output: ['cat', 'cat', 'cat']\n",
      "Input: This ,sentence.'' contains-£ no:: punctuation?\n",
      "Output: This sentence contains no punctuation\n",
      "Input: Cats & dogs\n",
      "Output: Cats and dogs\n"
     ]
    }
   ],
   "source": [
    "input_text = \"<b> This text is in bold</br>, <i> This text is in italics </i>\"\n",
    "output_text =  BeautifulSoup(input_text, \"html.parser\").get_text()\n",
    "print('Input: ' + input_text)\n",
    "print('Output: ' + output_text)\n",
    "\n",
    "input_text = ['Cat','cat','CAT']\n",
    "output_text =  [x.lower() for x in input_text]\n",
    "print('Input: ' + str(input_text))\n",
    "print('Output: ' + str(output_text))\n",
    "\n",
    "input_text = \"This ,sentence.'' contains-£ no:: punctuation?\"\n",
    "output_text = re.sub(r'[^\\w\\s]', '', input_text)\n",
    "print('Input: ' + input_text)\n",
    "print('Output: ' + output_text)\n",
    "\n",
    "input_text = \"Cats & dogs\"\n",
    "output_text = input_text.replace(\"&\", \"and\")\n",
    "print('Input: ' + input_text)\n",
    "print('Output: ' + output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17afa11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kprasath/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import nltk.corpus\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc701a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55009b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"see\",\"saw\",\"cat\", \"cats\", \"stem\", \"stemming\",\"lemma\",\"lemmatization\",\"known\",\"knowing\",\"time\", \"timing\",\"football\", \"footballers\"]\n",
    "for word in word_list:\n",
    "    print(word + ' -> ' + porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentenceStemmer(sentence):\n",
    "    tokens=word_tokenize(sentence)\n",
    "    stems=[porter.stem(word) for word in tokens]\n",
    "    return \" \".join(stems)\n",
    "\n",
    "SentenceStemmer('The cats and dogs are running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8208c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize('horses'))\n",
    "print(wordnet_lemmatizer.lemmatize('wolves'))\n",
    "print(wordnet_lemmatizer.lemmatize('mice'))\n",
    "print(wordnet_lemmatizer.lemmatize('cacti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(wordnet_lemmatizer.lemmatize('madeupwords'))\n",
    "print(porter.stem('madeupwords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordnet_lemmatizer.lemmatize('ran'))\n",
    "print(wordnet_lemmatizer.lemmatize('run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence = 'The cats and dogs are running'\n",
    "\n",
    "def return_word_pos_tuples(sentence):\n",
    "    return nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "\n",
    "return_word_pos_tuples(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pos_wordnet(pos_tag):\n",
    "    pos_dict = {\"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"J\": wordnet.ADJ,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return pos_dict.get(pos_tag[0].upper(), wordnet.NOUN)\n",
    "\n",
    "get_pos_wordnet('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e54917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize_with_pos(sentence):\n",
    "    new_sentence = []\n",
    "    tuples = return_word_pos_tuples(sentence)\n",
    "    for tup in tuples:\n",
    "        pos = get_pos_wordnet(tup[1])\n",
    "        lemma = wordnet_lemmatizer.lemmatize(tup[0], pos=pos)\n",
    "        new_sentence.append(lemma)\n",
    "    return new_sentence\n",
    "\n",
    "print(lemmatize_with_pos(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e4fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f4c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
