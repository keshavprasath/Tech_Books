{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a3f886",
   "metadata": {},
   "source": [
    "# Chapter 6: Convolutional Neural Networks for Text Classification (Notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0861acc",
   "metadata": {},
   "source": [
    "- RNNs arent the only model that can be used for text classification, CNN also works\n",
    "- RNN rely on sequential modeling, maintaining a hidden state and then step seqentially through the text word by word (in order), and updating weights at each iteration.\n",
    "- CNN do not rely on sequential element of language but tries to learn but understanding each word in context with its surrounding sentence.\n",
    "- CNNs mostly used for images but works reasonable well on text as well\n",
    "- logic being: meaning of individual words in the sentence depends on their context and the words they appear next to\n",
    "\n",
    "### Exploring CNNs\n",
    "- basics come from CV, but can be extended to NLP\n",
    "- intuition being sentence (left to right) and image (group of pixels)\n",
    "- so the individual pixels do not mean much but how its relationship to one another is important\n",
    "\n",
    "### Convolution for images\n",
    "- basic concept behind CNN is convolutions\n",
    "- A convolution is essentially a sliding window function that's applied to a matrix in order to capture information from the surrounding pixels\n",
    "- how it works is that for a large imagine, we use a kernal function that goes over the image as a matrix, do some operation and produce a new resulting image which contains infomation about our original image or matrix of pixels\n",
    "- in large image/complex sentences, we also add a pooling layer \n",
    "- pooling layer further reduces dimentionality (which is helpful)\n",
    "- pooling layer adds a function (usually a max function) to the outout of the Convolution layer to reduce dim.\n",
    "- this function is added over a sliding window, where the convo layer do not over lap\n",
    "- pooling layers shown to effectively reduce dim. of data which still retainging essential infomation\n",
    "\n",
    "Quick summary\n",
    "- kernal operation is like a sliding window that using all pixels and does some operands\n",
    "- pooling layer, used a function (usually max) and selects 1 value from the matrix which helps reduce dimentionality.\n",
    "\n",
    "Two main advatanges to using convolutions in this context\n",
    "- 1) able to compose a series of low-level featur into high-level feature (feature reduction)\n",
    "- 2) makes our model location invariant (edge detection, same features will be picked up)\n",
    "\n",
    "### Convolutions for NLP\n",
    "- since words can be vectors and sentence as a sequence of vectors. our corpus or text can be a matrix\n",
    "- main logic: if we can convolve over a sentence in a way that allows us to capture the relation of one word to the words around it, we can theoretically detect patterns in language and use this to better classify our sentences.\n",
    "- Convolutions in NLP is slightly different to images in that we now want to perform convolution layer accross whole word vecors than within word vectors\n",
    "- benefit is that there sint a limit to the number of ngrams we can convolve over and also be able to convolve multiple different ngrams simultaniously\n",
    "- for eg, can capture both bi-gram and trigrams given specific architecture\n",
    "- they also have their drawbacks: \n",
    "- unlike images where a pixel is most likely only related to its surrounding pixel\n",
    "-  a word in a sentence can be related to its surrounding as well as something as the end of the sentence (this is captured in the RNN architecture using longer-term memory dependnency) but CNNs may struggle as it only captures local surroundings of target words\n",
    "\n",
    "- however, CNN for nlp has been proven to perform well in certain tasks\n",
    "- main advantage of CNNs for NLP is its speed and efficiency\n",
    "- Convolutions can be easily impllement on GPUs for easier and fast parallelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238ce76",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94bf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext.legacy (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext.legacy\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install torchtext.legacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5133b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558771e8",
   "metadata": {},
   "source": [
    "- Aim to build a multi-class text classification (6 targets)\n",
    "- A question answering data set (https://trec.nist.gov/data/qa.html)\n",
    "- which is commonly used to evaluate the performance of a models text-classification tasks\n",
    "- model now returns a probability for each of the six possible classes (pick highest)\n",
    "- \n",
    "\n",
    "NOTE:\n",
    "- normally, we can view our datasets but here we are dealing with a TorchText dataset object\n",
    "- use train_data.examples[0].text and train_data.examples[0].label to view data contents\n",
    "- neural network will not take raw text as an input, turn into some form of embedding representation\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56375f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c61c41",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext' has no attribute 'legacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m questions \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mField(tokenize \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspacy\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mLabelField(dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext' has no attribute 'legacy'"
     ]
    }
   ],
   "source": [
    "questions = torchtext.legacy.data.Field(tokenize = 'spacy', batch_first = True)\n",
    "labels = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd780a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _ = datasets.TREC.splits(questions, labels)\n",
    "\n",
    "train_data, valid_data = train_data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.examples[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.examples[0].label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions.build_vocab(train_data,\n",
    "                 vectors = \"glove.6B.200d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "labels.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8966035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ddac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = 64, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c54fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        emb = self.embedding(text).unsqueeze(1)\n",
    "        \n",
    "        conved = [F.relu(c(emb)).squeeze(3) for c in self.convs]\n",
    "                \n",
    "        pooled = [F.max_pool1d(c, c.shape[2]).squeeze(2) for c in conved]\n",
    "        \n",
    "        concat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "            \n",
    "        return self.fc(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deecea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimensions = len(questions.vocab)\n",
    "output_dimensions = 6\n",
    "embedding_dimensions = 200\n",
    "pad_index = questions.vocab.stoi[questions.pad_token]\n",
    "\n",
    "number_of_filters = 100\n",
    "filter_sizes = [2,3,4]\n",
    "dropout_pc = 0.5\n",
    "\n",
    "\n",
    "model = CNN(input_dimensions, embedding_dimensions, number_of_filters, \n",
    "            filter_sizes, output_dimensions, dropout_pc, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = questions.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_index = questions.vocab.stoi[questions.unk_token]\n",
    "\n",
    "model.embedding.weight.data[unknown_index] = torch.zeros(embedding_dimensions)\n",
    "model.embedding.weight.data[pad_index] = torch.zeros(embedding_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2982e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_accuracy(preds, y):\n",
    "    pred = torch.max(preds,1).indices\n",
    "    correct = (pred == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa255ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(batch.text).squeeze(1)\n",
    "        loss = criterion(preds, batch.label.long())\n",
    "        \n",
    "        acc = multi_accuracy(preds, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    total_epoch_loss = epoch_loss / len(iterator)\n",
    "    total_epoch_accuracy = epoch_acc / len(iterator)\n",
    "        \n",
    "    return total_epoch_loss, total_epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            preds = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(preds, batch.label.long())\n",
    "            \n",
    "            acc = multi_accuracy(preds, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    total_epoch_loss = epoch_loss / len(iterator)\n",
    "    total_epoch_accuracy = epoch_acc / len(iterator)\n",
    "        \n",
    "    return total_epoch_loss, total_epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "lowest_validation_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    if valid_loss < lowest_validation_loss:\n",
    "        lowest_validation_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'cnn_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {int(end_time - start_time)}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
